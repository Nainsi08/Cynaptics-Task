# -*- coding: utf-8 -*-
"""subtask1final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/118Wkk8BoaZaRDAd4qP4jAtqtVS9hhHh2
"""

from google.colab import files
files.upload()  # Upload kaggle.json

!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions download -c induction-task-2025

!unzip induction-task-2025.zip

!unzip New_Data.zip

!ls Test_Images/

!pip install Pillow
!pip install keras-preprocessing
from keras.utils import to_categorical
from tensorflow.keras.utils import load_img
from keras.models import Sequential
from keras.applications import MobileNetV2, ResNet152, VGG16, EfficientNetB0, InceptionV3
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
import os
from sklearn.preprocessing import LabelEncoder
import pandas as pd
import numpy as np
from tqdm.notebook import tqdm
from PIL import Image, UnidentifiedImageError

def createdataframe(dir):
    image_paths = []
    labels = []
    for label in os.listdir(dir):
        for imagename in os.listdir(os.path.join(dir, label)):
            image_paths.append(os.path.join(dir, label, imagename))
            labels.append(label)
        print(label, "completed")
    return image_paths, labels

def extract_features(images):
    features = []
    for image in tqdm(images):
        try:
            # Open the image directly using PIL
            img = Image.open(image)
            img = img.resize((236, 236))  # Resize using PIL
            img = np.array(img)
            features.append(img)
        except (UnidentifiedImageError, OSError) as e: # Use UnidentifiedImageError directly
            print(f"Error processing image {image}: {e}")
            continue  # Skip the problematic image and continue with others
    features = np.array(features)
    features = features.reshape(features.shape[0], 236, 236, 3)  # Reshape all images in one go
    return features

TRAIN_DIR = "New_Data"
TEST_DIR = "Test_Images"

train = pd.DataFrame()

train['image'], train['label'] = createdataframe(TRAIN_DIR)

train = train[~train['image'].isin(['New_Data/1/image_408.jpg','New_Data/0/image_394.jpg'])]


train_features = extract_features(train['image'])

valid_indices = []
for i, image in enumerate(train['image']):
    try:
        img = Image.open(image)
        img = img.resize((236, 236))
        valid_indices.append(i)
    except (UnidentifiedImageError, OSError) as e:
        print(f"Skipping {image}: {e}")
        continue

train = train.iloc[valid_indices].reset_index(drop=True)

x_train = train_features / 255.0

le = LabelEncoder()
y_train = le.fit_transform(train['label'])
y_train = to_categorical(y_train, num_classes=2)

print("x_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)

model = Sequential()
# Convolutional layers
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(236, 236, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(1024, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(2048, activation='relu'))
model.add(Dense(2, activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=25, epochs=25)

from tensorflow.keras.preprocessing.image import img_to_array

def prepare_test_data(test_dir, target_size=(236, 236)):
    # Get all image files and sort them numerically
    img_files = os.listdir(test_dir)

    # Custom sort key function to handle numerical sorting
    def get_img_number(filename):
        # Extract number from image_X.jpg format
        return int(filename.split('_')[1].split('.')[0])

    # Sort files numerically
    img_files.sort(key=get_img_number)

    test_images = []
    test_ids = []

    # Process images in sorted order
    for img_name in tqdm(img_files, desc="Processing test images"):
        img_path = os.path.join(test_dir, img_name)

        try:
            # Verify if file exists
            if not os.path.exists(img_path):
                print(f"Warning: File not found: {img_path}")
                continue

            # Check if file is empty
            if os.path.getsize(img_path) == 0:
                print(f"Warning: Empty file: {img_path}")
                continue

            # Try to open and verify the image
            img = load_img(img_path, target_size=target_size)

            # Convert to array and check if valid
            img_array = img_to_array(img)

            # Check if array has valid dimensions
            if img_array.shape != (*target_size, 3):
                print(f"Warning: Invalid image dimensions for {img_path}")
                continue

            # Normalize and append
            img_array = img_array / 255.0
            test_images.append(img_array)

            # Remove .jpg extension from image name
            clean_id = img_name.split('.')[0]
            test_ids.append(clean_id)

        except Exception as e:
            print(f"Error processing {img_path}: {str(e)}")
            continue

    if not test_images:
        raise ValueError("No valid images found in the test directory!")

    print(f"Successfully processed {len(test_images)} images")
    return np.array(test_images), test_ids

# Let's add some diagnostic information before processing
print(f"Test directory path: {TEST_DIR}")
print(f"Files in test directory: {os.listdir(TEST_DIR)[:5]} ... (showing first 5)")
print(f"Total files found: {len(os.listdir(TEST_DIR))}")

# Prepare test data with ordered images
x_test, test_ids = prepare_test_data(TEST_DIR)

# Predict labels for the test set
predictions = model.predict(x_test)
predicted_classes = np.argmax(predictions, axis=1)
predicted_labels = le.inverse_transform(predicted_classes)

# Create submission dataframe
submission_df = pd.DataFrame({
    'Id': test_ids,  # These IDs now don't have .jpg extension
    'Label': predicted_labels
})

# Add additional verification
print("\nSubmission DataFrame Info:")
print(submission_df.info())
print("\nFirst 5 rows:")
print(submission_df.head())
print("\nLast 5 rows:")
print(submission_df.tail())

# Save the submission file
submission_df.to_csv('submission.csv', index=False)
print("\nSubmission file saved as 'submission.csv'")